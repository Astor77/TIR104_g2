# #ä½¿ç”¨mapping_close_true.csv,è·‘release_dates 
# import pandas as pd
# import requests
# import time
# import os

# # è®€å– mapping_close_true.csv
# file_path = "/workspaces/TIR104_g2/P_Rain/Release_Date/min_1/v3_test5.csv"  # ç¢ºä¿è·¯å¾‘
# df = pd.read_csv(file_path)

# # æª¢æŸ¥æ˜¯å¦æœ‰ tmdb_id æ¬„ä½
# if "id" not in df.columns:
#     raise ValueError("CSV æª”æ¡ˆç¼ºå°‘ 'id' æ¬„ä½ï¼")

# # è¨­å®š TMDB API
# API_KEY = "eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiI1MGRjN2NlNjBjNjBkODhkMDdhMGI3OWYzY2RlNjM4OCIsIm5iZiI6MTczNjkzOTg1NC4yODEsInN1YiI6IjY3ODc5OTRlYmQ3OTNjMDM1NDRmMjE3NiIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.-pibOcIPWjgSH1lNk_rhCRVstS21H1hV5nEPLpAdHfE"  # é€™è£¡å¡«å…¥ TMDB API KEY
# HEADERS = {
#     "Authorization": f"Bearer {API_KEY}",
#     "accept": "application/json"
# }
# BASE_URL = "https://api.themoviedb.org/3/movie/{}/release_dates"

# # å„²å­˜çµæœçš„åˆ—è¡¨
# release_dates = []

# # å–å¾—å”¯ä¸€çš„ TMDB ID
# _ids = df["id"].dropna().astype(int).unique()

# # æŸ¥è©¢ API
# for idx, id in enumerate(_ids):
#     url = BASE_URL.format(id)
#     response = requests.get(url, headers=HEADERS)
    
#     if response.status_code == 200:
#         data = response.json()
#         for result in data.get("results", []):
#             country = result.get("iso_3166_1")
#             for release in result.get("release_dates", []):
#                 release_dates.append({
#                     "tmdb_id": id,
#                     "country": country,
#                     "certification": release.get("certification", ""),
#                     "descriptors": release.get("descriptors", []),
#                     "iso_639_1": release.get("iso_639_1", ""),
#                     "note" : release.get("note"),
#                     "release_date": release.get("release_date"),
#                     "type": release.get("type")
#                 })

#     else:
#         print(f"æŸ¥è©¢å¤±æ•—: {id}, ç‹€æ…‹ç¢¼: {response.status_code}")

#     # åŠ å…¥å»¶é²ï¼Œé¿å… API é™åˆ¶
#     time.sleep(0.5)

# # è½‰æ›ç‚º DataFrame
# df_v3_test5_release_dates = pd.DataFrame(release_dates)

# # å„²å­˜åˆ° CSV
# csv_path = csv_path = "v3_test5_release_dates.csv"
# df_v3_test5_release_dates.to_csv(csv_path, index=False, encoding="utf-8-sig")

# # ç¢ºä¿ CSV çœŸçš„å¯«å…¥æˆåŠŸ
# if os.path.exists("release_dates.csv"):
#     print("v3_test5_release_dates.csv æª”æ¡ˆæˆåŠŸå„²å­˜ï¼")
# else:
#     print("v3_test5_release_dates.csv å„²å­˜å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ¬Šé™æˆ–ç›®éŒ„ï¼")

# import os

# file_path = "release_dates.csv"

# # æª¢æŸ¥ç•¶å‰ç›®éŒ„çš„æ‰€æœ‰æª”æ¡ˆ
# print("ğŸ“‚ ç›®å‰ç›®éŒ„æª”æ¡ˆåˆ—è¡¨ï¼š", os.listdir("."))

# # ç¢ºèªæª”æ¡ˆæ˜¯å¦å­˜åœ¨
# if os.path.exists(file_path):
#     print(f"âœ… æª”æ¡ˆ '{file_path}' å­˜åœ¨ï¼")
# else:
#     print(f"âŒ æª”æ¡ˆ '{file_path}' ä¸å­˜åœ¨ï¼Œè«‹æª¢æŸ¥å­˜æ”¾è·¯å¾‘ï¼")

import os
import glob

# ç²å–ç•¶å‰å·¥ä½œç›®éŒ„
current_directory = os.getcwd()
print(f"ç›®å‰å·¥ä½œç›®éŒ„: {current_directory}")

# æœå°‹æ‰€æœ‰ .csv æª”æ¡ˆ
csv_files = glob.glob("**/v3_test5.csv", recursive=True)

# é¡¯ç¤ºæœå°‹çµæœ
if csv_files:
    print("æ‰¾åˆ° v3_test5.csvï¼Œä½ç½®å¦‚ä¸‹ï¼š")
    for file in csv_files:
        print(f" {os.path.abspath(file)}")
else:
    print("æœªæ‰¾åˆ° v3_test5.csvï¼Œè«‹ç¢ºèªæ˜¯å¦æˆåŠŸå„²å­˜ï¼")
