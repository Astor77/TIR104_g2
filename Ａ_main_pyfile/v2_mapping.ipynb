{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "\n",
    "# 這邊應該可以優化成一個for 迴圈，開啟指定資料夾內的檔案\n",
    "\n",
    "file_path = \"/workspaces/TIR104_g2/2022 年票房資料.json\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "    data_22 = json.load(f)\n",
    "\n",
    "file_path = \"/workspaces/TIR104_g2/2023 年票房資料.json\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "    data_23 = json.load(f)\n",
    "\n",
    "file_path = \"/workspaces/TIR104_g2/2024 年票房資料.json\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "    data_24 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將JSON檔案轉成df，並只先篩選[\"MovieId\", \"Name\"]\n",
    "data_items = data_22.get(\"DataItems\")\n",
    "df_tw_2022 = pd.DataFrame(data_items)\n",
    "df_tw_2022[\"Name\"] = df_tw_2022[\"Name\"].str.split(\"(\").str[0]\n",
    "df_tw_2022[\"Year\"] = \"2022\"\n",
    "df_tw_2022 = df_tw_2022.loc[:,[\"Year\", \"MovieId\", \"Name\"]]\n",
    "\n",
    "data_items = data_23.get(\"DataItems\")\n",
    "df_tw_2023 = pd.DataFrame(data_items)\n",
    "df_tw_2023[\"Name\"] = df_tw_2023[\"Name\"].str.split(\"(\").str[0]\n",
    "df_tw_2023[\"Year\"] = \"2023\"\n",
    "df_tw_2023 = df_tw_2023.loc[:,[\"Year\", \"MovieId\", \"Name\"]]\n",
    "\n",
    "data_items = data_24.get(\"DataItems\")\n",
    "df_tw_2024 = pd.DataFrame(data_items)\n",
    "df_tw_2024[\"Name\"] = df_tw_2024[\"Name\"].str.split(\"(\").str[0]\n",
    "df_tw_2024[\"Year\"] = \"2024\"\n",
    "df_tw_2024 = df_tw_2024.loc[:,[\"Year\", \"MovieId\", \"Name\"]]\n",
    "\n",
    "df_tw_2022_to_2024_t = pd.concat([df_tw_2022, df_tw_2023, df_tw_2024]).reset_index(drop=True)\n",
    "df_tw_2022_to_2024_t.to_csv(\"df_tw_2022_to_2024_t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%E7%B7%8A%E6%80%A5%E8%BF%AB%E9%99%8D\n",
      "%E6%A9%9F%E5%AF%86%E5%90%8C%E7%9B%9F2\n",
      "%E9%9F%B3%E7%88%86%E6%B5%A9%E5%8A%AB\n"
     ]
    }
   ],
   "source": [
    "# 測試名稱能夠順利轉換成url coding\n",
    "for i in range(3):\n",
    "    name = df_tw_2022_to_2024_t[\"Name\"][i]\n",
    "    name_to_unicode = urllib.parse.quote(name)\n",
    "    print(name_to_unicode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tmdb_mapping_result(name: str) -> list:\n",
    "    \"\"\"\n",
    "    name: taiwan movie name\n",
    "    list: collect all of the search results for this name\n",
    "    \"\"\"\n",
    "    name_to_unicode = urllib.parse.quote(name)\n",
    "    url = f\"https://api.themoviedb.org/3/search/movie?query={name_to_unicode}&language=zh-TW&region=TW&page=1\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": \"Bearer eyJhbGciOiJIUzI1NiJ9.eyJhdWQiOiJmYjIzOTQ0ZWY2ZWQyNzA1YmFlY2E4NzNmZDU4NTdiOSIsIm5iZiI6MTczNjM1NTM1My4yODgsInN1YiI6IjY3N2VhZTE5NDRkNjQ5ZmZhZTdiMTI1MSIsInNjb3BlcyI6WyJhcGlfcmVhZCJdLCJ2ZXJzaW9uIjoxfQ.2hnj7FRsE5MemKe5-OGGouZ2oy7pjQLEygptA0WFqpM\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers).json()\n",
    "    movie_results = []\n",
    "    if response[\"results\"]:\n",
    "        for item in response[\"results\"]:\n",
    "            movie_results.append([name, item[\"id\"], item[\"title\"]])\n",
    "        return movie_results\n",
    "    else:\n",
    "        movie_results.append([name, \"NotFound\", \"NotFound\"])\n",
    "        return movie_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query 的結果製成dataframe\n",
    "columns = [\"tw_title\", \"tmdb_id\", \"tmdb_title\"]\n",
    "data = []\n",
    "\n",
    "for name in df_tw_2022_to_2024_t[\"Name\"]:\n",
    "    try:\n",
    "        movie = get_tmdb_mapping_result(name)\n",
    "        data.extend(movie)\n",
    "    except Exception as err:\n",
    "        print(f\"there's a search error for {name}: {err}\")\n",
    "        data.extend([[name, \"err\", \"err\" ]])\n",
    "    finally:\n",
    "        time.sleep(0.5)\n",
    "\n",
    "df_tmdb = pd.DataFrame(data=data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始搜尋的結果\n",
    "df_tmdb\n",
    "df_tmdb.to_csv(\"v1_search_result_total_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 篩選掉重複tmdb_id跟tmdb_title，跟tw表merge\n",
    "\n",
    "df_merge = df_tw_2022_to_2024_t.merge(\n",
    "    df_tmdb.drop_duplicates(subset=[\"tmdb_id\", \"tmdb_title\"]).loc[:, [\"tmdb_id\", \"tmdb_title\"]],\n",
    "    how=\"left\",\n",
    "    #左邊的表（different）用哪個欄位\n",
    "    left_on=\"Name\",\n",
    "    #右邊的表（different）用哪個欄位\n",
    "    right_on=\"tmdb_title\",\n",
    ")\n",
    "\n",
    "df_merge.to_csv(\"v1_mapping_drop_dup_tmdb_id.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因為有不同id但相同的電影名稱，試試看無條件只保留第一個\n",
    "\n",
    "df_merge = df_tw_2022_to_2024_t.merge(\n",
    "    df_tmdb.drop_duplicates(subset=[\"tmdb_title\"]).loc[:, [\"tmdb_id\", \"tmdb_title\"]],\n",
    "    how=\"left\",\n",
    "    #左邊的表（different）用哪個欄位\n",
    "    left_on=\"Name\",\n",
    "    #右邊的表（different）用哪個欄位\n",
    "    right_on=\"tmdb_title\",\n",
    ")\n",
    "\n",
    "df_merge.to_csv(\"v1_mapping_drop_dup_tmdb_title.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping fail: 686 rows\n",
      "mapping assumed success: 1951 rows\n"
     ]
    }
   ],
   "source": [
    "nan_count = df_merge[\"tmdb_id\"].isna().sum()\n",
    "success_count = df_merge[\"tmdb_id\"].notna().sum()\n",
    "print(f\"mapping fail: {nan_count} rows\")\n",
    "print(f\"mapping assumed success: {success_count} rows\")\n",
    "\n",
    "df_merge.to_csv(\"v1_mapping_raw_t.csv\")\n",
    "df_merge[df_merge[\"tmdb_id\"].isna()].to_csv(\"v1_mapping_false_t.csv\")\n",
    "df_merge[df_merge[\"tmdb_id\"].notna()].to_csv(\"v1_mapping_close_true_t.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
